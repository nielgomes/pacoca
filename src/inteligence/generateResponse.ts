//src/inteligence/generateResponse.ts
import { ChatCompletionMessageParam, ChatCompletionTool } from "openai/resources";
import { openai } from "../services/openai";
import { Data } from "../utils/database";
import beautifulLogger from "../utils/beautifulLogger";
import models from '../../model.json';
import config from "../utils/config";
import mediaCatalog from '../../media_catalog.json';
import { Message, BotResponse, GenerateResponseResult, BotAction } from "./types";
import PERSONALITY_PROMPT from "../constants/PERSONALITY_PROMPT";


// --- Carregamento √önico de M√≠dia ---
const stickerOptions = mediaCatalog.stickers.map(sticker => sticker.file);
const audioOptions = mediaCatalog.audios.map(audio => audio.file);
const memeOptions = mediaCatalog.memes.map(meme => meme.file);

/**
 * Estima o n√∫mero de tokens para um determinado texto.
 */
function calculateTokens(text: string): number {
  // O 'tiktoken' √© espec√≠fico para modelos OpenAI. Usamos uma aproxima√ß√£o
  // gen√©rica (caracteres / 4) para evitar erros com outros modelos.
  return Math.ceil(text.length / 4);
}

/**
 * Formata os dados de contexto (resumo e opini√µes) para o prompt da IA.
 */
const formatDataForPrompt = (data: Data): string => {
  let formattedData = "Resumo da conversa e opini√µes dos usu√°rios:\n\n";
  if (data.summary) {
    formattedData += `üìã RESUMO DA CONVERSA:\n${data.summary}\n\n`;
  }
  if (data.opinions && data.opinions.length > 0) {
    formattedData += `üë• OPIN√ïES SOBRE OS USU√ÅRIOS:\n`;
    data.opinions.forEach((opinion) => {
      let opinionText = "NEUTRO/MISTO";
      if (opinion.opinion < 20) opinionText = "ODEIO ELE";
      else if (opinion.opinion < 40) opinionText = "N√ÉO GOSTO";
      else if (opinion.opinion < 60) opinionText = "NEUTRO/MISTO";
      else if (opinion.opinion < 80) opinionText = "GOSTO BASTANTE";
      else if (opinion.opinion <= 100) opinionText = "APAIXONADA";
      formattedData += `‚Ä¢ ${opinion.name} (${opinion.jid}):\n`;
      formattedData += `  - N√≠vel de opini√£o: ${opinion.opinion}/100 (${opinionText})\n`;
      if (opinion.traits?.length) {
        formattedData += `  - Caracter√≠sticas: ${opinion.traits.join(", ")}\n`;
      }
      formattedData += "\n";
    });
  }
  return formattedData.trim();
};

// --- DEFINI√á√ÉO DAS FERRAMENTAS ---
const tools: ChatCompletionTool[] = [
  {
    type: "function",
    function: {
      name: "send_message",
      description: "Envia uma mensagem de texto no chat.",
      parameters: {
        type: "object",
        properties: {
          text: {
            type: "string",
            description: "O conte√∫do da mensagem de texto a ser enviada (m√°x 300 caracteres).",
          },
          reply_to_id: {
            type: "string",
            description: "O ID da mensagem √† qual esta mensagem deve responder (opcional).",
          },
        },
        required: ["text"],
      },
    },
  },
  {
    type: "function",
    function: {
      name: "send_sticker",
      description: "Envia um sticker (figurinha) para expressar uma emo√ß√£o.",
      parameters: {
        type: "object",
        properties: {
          sticker_name: {
            type: "string",
            description: "O nome exato do arquivo do sticker (ex: 'feliz.webp').",
            enum: stickerOptions, // Usamos a lista carregada do mediaCatalog
          },
        },
        required: ["sticker_name"],
      },
    },
  },
    {
    type: "function",
    function: {
      name: "send_audio",
      description: "Envia um meme de √°udio curto (.mp3).",
      parameters: {
        type: "object",
        properties: {
          audio_name: {
            type: "string",
            description: "O nome exato do arquivo de √°udio (ex: 'WINDOWS-STARTUP.mp3').",
            enum: audioOptions,
          },
        },
        required: ["audio_name"],
      },
    },
  },
  {
    type: "function",
    function: {
      name: "send_meme_image",
      description: "Envia uma imagem de meme (.jpg).",
      parameters: {
        type: "object",
        properties: {
          meme_name: {
            type: "string",
            description: "O nome exato do arquivo da imagem do meme (ex: 'ai-que-burro-da-zero-pra-ele.jpg').",
            enum: memeOptions,
          },
        },
        required: ["meme_name"],
      },
    },
  },
  {
    type: "function",
    function: {
      name: "create_poll",
      description: "Cria uma enquete no chat.",
      parameters: {
        type: "object",
        properties: {
          question: { type: "string", description: "A pergunta da enquete." },
          options: {
            type: "array",
            description: "Uma lista de exatamente 3 op√ß√µes de texto para a enquete.",
            items: { type: "string" },
            minItems: 3,
            maxItems: 3,
          },
        },
        required: ["question", "options"],
      },
    },
  },
  {
    type: "function",
    function: {
      name: "send_location",
      description: "Envia uma localiza√ß√£o geogr√°fica.",
      parameters: {
        type: "object",
        properties: {
          latitude: { type: "number", description: "A latitude." },
          longitude: { type: "number", description: "A longitude." },
        },
        required: ["latitude", "longitude"],
      },
    },
  },
  {
    type: "function",
    function: {
      name: "send_contact",
      description: "Envia um cart√£o de contato.",
      parameters: {
        type: "object",
        properties: {
          name: { type: "string", description: "O nome a ser exibido no cart√£o de contato." },
          cell: { type: "string", description: "O n√∫mero de telefone no formato internacional (ex: +5561999999999)." },
        },
        required: ["cell", "name"], // Tornando name obrigat√≥rio aqui
      },
    },
  },
];


export default async function generateResponse(
  data: Data,
  messages: Message[],
  sessionId: string
): Promise<GenerateResponseResult> {
  beautifulLogger.aiGeneration("start", "Iniciando gera√ß√£o de resposta...");
  const messagesMaped = messages
    .map((message) => `${message.name}: ${message.content}`)
    .join("\n");

  beautifulLogger.aiGeneration("processing", {
    "mensagens processadas": messages.length,
    "mensagem mais recente": messages.at(-1)?.content || "nenhuma",
  });

  // Contexto de m√≠dia e dados (permanecem iguais)
  let mediaContext = "INFORMA√á√ïES SOBRE M√çDIAS DISPON√çVEIS PARA USO:\n\n";
  // ... (c√≥digo para montar mediaContext inalterado) ...
  mediaContext += "STICKERS DISPON√çVEIS:\n";
  mediaCatalog.stickers.forEach(s => {
    mediaContext += `- arquivo: "${s.file}", descri√ß√£o: "${s.description}"\n`;
  });
  mediaContext += "\n√ÅUDIOS DISPON√çVEIS:\n";
  mediaCatalog.audios.forEach(a => {
    mediaContext += `- arquivo: "${a.file}", descri√ß√£o: "${a.description}"\n`;
  });
  mediaContext += "\nMEMES DISPON√çVEIS:\n";
  mediaCatalog.memes.forEach(m => {
    mediaContext += `- arquivo: "${m.file}", descri√ß√£o: "${m.description}"\n`;
  });
  const groupData = data[sessionId] || {};
  const contextData = formatDataForPrompt(groupData);

  // Acessamos o modelo principal da config simplificada
  const modelsData = models as Record<string, { MODEL_NAME: string; MODEL_PRICING: { input: number; output: number; } }>;
  const modelConfig = modelsData[config.MAIN_MODEL];
  const MODEL_NAME = modelConfig.MODEL_NAME;
  const MODEL_PRICING = modelConfig.MODEL_PRICING;

  beautifulLogger.aiGeneration("mode", `Executando no modo TOOL CALLING com modelo: ${MODEL_NAME}`);

  // Montamos as mensagens para a IA
  const inputMessages: ChatCompletionMessageParam[] = [
    { role: "system", content: PERSONALITY_PROMPT }, // Prompt simplificado
    { role: "assistant", content: `${contextData}\n\n${mediaContext}` },
    { role: "user", content: `Hist√≥rico da Conversa:\n\n${messagesMaped}\n\n---\nCom base na conversa e na sua personalidade, escolha quais ferramentas usar (se alguma).` },
  ];
  
  const inputText = inputMessages.map((msg) => msg.content || '').join("\n");
  const inputTokens = calculateTokens(inputText);

  beautifulLogger.aiGeneration("tokens", { "tokens de entrada (estimado)": inputTokens });
  beautifulLogger.aiGeneration("processing", `Enviando requisi√ß√£o com ferramentas para: ${MODEL_NAME}`);
  
  
try {
    // --- CHAMADA DA API COM FERRAMENTAS ---
    const response = await openai.chat.completions.create({
      model: MODEL_NAME,
      messages: inputMessages,
      tools: tools, // Enviamos a defini√ß√£o das ferramentas
      tool_choice: "auto", // Deixamos a IA decidir se e qual ferramenta usar
      temperature: 0.7, // Um pouco menos de temperatura pode ajudar com tool calling
      max_tokens: 500, // Ajuste conforme necess√°rio, mas tool calls s√£o mais curtos
    }, {
      timeout: 45 * 1000, // Aumentar um pouco o timeout pode ser bom
    });

    const responseMessage = response.choices[0]?.message;
    if (!responseMessage) {
      throw new Error("A IA n√£o retornou nenhuma mensagem de resposta.");
    }

    // Calculamos custo e tokens (simplificado, APIs podem cobrar por tool calls de forma diferente)
    const outputContent = JSON.stringify(responseMessage.tool_calls || responseMessage.content || '');
    const outputTokens = calculateTokens(outputContent);
    const totalTokens = inputTokens + outputTokens;
    const cost = (inputTokens * MODEL_PRICING.input / 1000000) + (outputTokens * MODEL_PRICING.output / 1000000);
    const costResult = { inputTokens, outputTokens, totalTokens, cost };
    const costMessage = cost === 0 ? `$${cost.toFixed(8)} (modelo gratuito)` : `$${cost.toFixed(8)}`;

     beautifulLogger.aiGeneration("cost", {
          "modelo utilizado": MODEL_NAME,
          "tokens entrada (est.)": inputTokens,
          "tokens sa√≠da (est.)": outputTokens,
          "tokens total (est.)": totalTokens,
          "custo (USD)": costMessage,
     });

    // --- PROCESSAMENTO DA RESPOSTA COM TOOL CALLING ---
    const toolCalls = responseMessage.tool_calls;
    const finalActions: BotAction[] = [];

    if (toolCalls && toolCalls.length > 0) {
      beautifulLogger.aiGeneration("processing", `IA solicitou ${toolCalls.length} chamada(s) de ferramenta.`);

      for (const toolCall of toolCalls) {
        const functionName = toolCall.function.name;
        const rawArgsString = toolCall.function.arguments;
        let functionArgs: any;
        try {
            let jsonStringToParse = rawArgsString;

            // Tentativa de extrair apenas o objeto JSON principal da string
            const firstBrace = rawArgsString.indexOf('{');
            const lastBrace = rawArgsString.lastIndexOf('}');
            if (firstBrace !== -1 && lastBrace !== -1 && lastBrace > firstBrace) {
                // Extrai o conte√∫do entre o primeiro { e o √∫ltimo }
                jsonStringToParse = rawArgsString.substring(firstBrace, lastBrace + 1);
                if (rawArgsString !== jsonStringToParse) {
                     beautifulLogger.warn("TOOL_CALL_CLEAN", `Limpando string de argumentos potencialmente suja para ${functionName}. Original: "${rawArgsString}", Limpa: "${jsonStringToParse}"`);
                }
            } else {
                 beautifulLogger.warn("TOOL_CALL_FORMAT", `String de argumentos para ${functionName} n√£o parece conter um objeto JSON v√°lido: "${rawArgsString}"`);
                 // Mesmo assim, tentamos parsear a string original, pode ser um JSON simples (ex: "true")
            }

            // Tentamos parsear a string (original ou limpa)
            functionArgs = JSON.parse(jsonStringToParse);
        } catch (e: any) {
            // Se mesmo ap√≥s a limpeza o parse falhar, logamos e pulamos
            beautifulLogger.error("TOOL_CALL_PARSE", `Erro FINAL ao parsear argumentos para ${functionName} mesmo ap√≥s limpeza.`, {
                original_args: rawArgsString,
                error_message: e.message
             });
            continue;
        }

        // Convertemos a chamada da ferramenta para o nosso formato BotAction
        if (functionName === 'send_message' && functionArgs.text) {
          finalActions.push({
            type: 'message',
            message: { text: functionArgs.text, reply: functionArgs.reply_to_id },
          });
        } else if (functionName === 'send_sticker' && functionArgs.sticker_name) {
          finalActions.push({ type: 'sticker', sticker: functionArgs.sticker_name });
        } else if (functionName === 'send_audio' && functionArgs.audio_name) {
          finalActions.push({ type: 'audio', audio: functionArgs.audio_name });
        } else if (functionName === 'send_meme_image' && functionArgs.meme_name) {
           finalActions.push({ type: 'meme', meme: functionArgs.meme_name });
        } else if (functionName === 'create_poll' && functionArgs.question && functionArgs.options) {
           finalActions.push({ type: 'poll', poll: { question: functionArgs.question, options: functionArgs.options } });
        } else if (functionName === 'send_location' && functionArgs.latitude && functionArgs.longitude) {
           finalActions.push({ type: 'location', location: { latitude: functionArgs.latitude, longitude: functionArgs.longitude } });
        } else if (functionName === 'send_contact' && functionArgs.cell && functionArgs.name) {
           finalActions.push({ type: 'contact', contact: { name: functionArgs.name, cell: functionArgs.cell } });
        } else {
            beautifulLogger.warn("TOOL_CALL_UNKNOWN", `IA chamou uma ferramenta desconhecida ou com argumentos inv√°lidos: ${functionName}`);
        }
      }
    } else {
        // Se a IA n√£o chamou nenhuma ferramenta, ela pode ter respondido com texto normal.
        // Podemos tratar isso como uma mensagem ou simplesmente ignorar (prefer√≠vel se ela deveria usar ferramentas).
        if (responseMessage.content) {
             beautifulLogger.warn("TOOL_CALL_MISSING", "IA respondeu com texto normal em vez de usar uma ferramenta.", { content: responseMessage.content });
             // Opcional: Poderia adicionar uma a√ß√£o de mensagem aqui, mas pode indicar erro no prompt.
             // finalActions.push({ type: 'message', message: { text: responseMessage.content } });
        } else {
            beautifulLogger.aiGeneration("complete", "IA decidiu n√£o tomar nenhuma a√ß√£o.");
        }
    }

    beautifulLogger.aiGeneration("complete", {
        "a√ß√µes processadas": finalActions.length,
        "tipos de a√ß√£o": finalActions.map((a) => a.type).join(", ") || "Nenhuma",
    });

    return { actions: finalActions, cost: costResult };

  } catch (error: any) {
    beautifulLogger.aiGeneration("error", {
      erro: "Falha cr√≠tica na chamada da API ou no processamento da resposta.",
      "mensagem de erro": error.message,
    });
    // Lan√ßamos o erro para que o 'catch' principal em rapy.ts possa lidar com ele.
    throw error;
  }
}